# Tech Challenge 3


## üß© Componentes da Solu√ß√£o

A solu√ß√£o √© composta por tr√™s partes principais:

- Uma **API RESTful** desenvolvida com **FastAPI**, que organiza e exp√µe os dados em endpoints;
- Um m√≥dulo de **coleta automatizada** (`scraper/`), que realiza o scraping diretamente do site da Embrapa e armazena os dados em um banco local.
- Treinamento de um modelo LSTM (Long Short-Term Memory).


![Fluxo do modelo LSTM](docs/diagrama da arquitetura.png)


## üí° Finalidade

O projeto tem como foco:

- Facilitar o acesso a dados confi√°veis do setor vitivin√≠cola;
- Criar uma base s√≥lida para alimentar sistemas de intelig√™ncia anal√≠tica e modelos preditivos;
- Explorar boas pr√°ticas de engenharia de software e arquitetura de APIs em Python.

---

## üìÇ Estrutura do Projeto

# üß± Estrutura por Responsabilidade

Esta se√ß√£o descreve a organiza√ß√£o do projeto com base nas **responsabilidades funcionais** de cada m√≥dulo, abstraindo detalhes de arquivos individuais. A estrutura foi pensada para garantir **separa√ß√£o de preocupa√ß√µes**, **facilidade de manuten√ß√£o** e **expansibilidade futura**.

---

### 1. üß© N√∫cleo da Aplica√ß√£o (`app/`)
Cont√©m toda a l√≥gica da aplica√ß√£o FastAPI, incluindo controle de rotas, modelos de dados, schemas de valida√ß√£o e l√≥gica de neg√≥cio.

#### Subm√≥dulos:
- `routers/` ‚Üí Gerencia os endpoints expostos da API, organizados por dom√≠nio (ex: produ√ß√£o, importa√ß√£o, previs√£o).
- `models/` ‚Üí Define os modelos de dados que representam tabelas no banco (ORM com SQLAlchemy).
- `schemas/` ‚Üí Estrutura e valida os dados de entrada e sa√≠da da API (Pydantic), al√©m de gerar documenta√ß√£o Swagger autom√°tica.
- `database.py` ‚Üí Respons√°vel por configurar a conex√£o com o banco de dados e a sess√£o de uso.
- `main.py` ‚Üí Ponto de entrada da aplica√ß√£o (instancia o app e registra os routers).

---

### 2. M√≥dulo de Machine Learning (`app/ml/`)
Respons√°vel por toda a parte de processamento de dados e previs√µes com modelos de IA.

#### Subm√≥dulos:
- `models/` ‚Üí Armazena os arquivos de modelos treinados (ex: arquivos `.h5` para redes neurais).
- `preprocessing.py` ‚Üí Cont√©m fun√ß√µes auxiliares para transformar e preparar os dados antes da previs√£o.
- `services/` ‚Üí Implementa os servi√ßos de infer√™ncia, ou seja, como carregar o modelo e gerar uma previs√£o com os dados recebidos.

---

### 3. Scripts Auxiliares (`scripts/`)
Utilizado para tarefas administrativas como treinamento, limpeza de dados ou migra√ß√µes. N√£o fazem parte do ciclo de vida direto da API, mas s√£o fundamentais para prepara√ß√£o e manuten√ß√£o.


---

### 4. Documenta√ß√£o (`docs/`)
Cont√©m imagens, diagramas e arquivos auxiliares utilizados na documenta√ß√£o do projeto.

---

### 5. Arquivos de Configura√ß√£o (n√≠vel raiz)
- `.env` ‚Üí Armazena vari√°veis sens√≠veis (opcional).
- `requirements.txt` ‚Üí Lista de depend√™ncias Python.
- `README.md` ‚Üí Documenta√ß√£o geral do projeto.
- `.venv/` ‚Üí Ambiente virtual Python (fora do versionamento).

---

### ‚úÖ Benef√≠cios dessa Estrutura

- Organiza√ß√£o clara por responsabilidade
- Separa√ß√£o entre API, l√≥gica de neg√≥cio e IA/ML
- F√°cil manuten√ß√£o e testes
- Reutiliza√ß√£o de componentes
- Ader√™ncia a boas pr√°ticas de engenharia de software


---

## üöÄ Como Executar o Projeto

Siga os passos abaixo para executar a aplica√ß√£o localmente, incluindo a coleta e envio dos dados para a API. Lembre-se de que o scraper **n√£o grava direto no banco**, ele envia os dados para a API por meio de requisi√ß√µes HTTP.

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/AntonioJCS/fiap_tech_challenge_3.git
cd fiap_tech_challenge_3 # criei ese diret√≥rio em algum ponto da maquina
```

### 2. Crie e ative um ambiente virtual

```bash
python -m venv .venv
source .venv/Scripts/activate  # Git Bash no Windows
```

### 3. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Inicie a API

Antes de rodar o scraper, √© obrigat√≥rio iniciar a API, pois ela ser√° respons√°vel por receber e persistir os dados no banco de dados.

```bash
uvicorn app.main:app --reload
```

A API estar√° dispon√≠vel em `http://127.0.0.1:8000`

### 5. Autentique-se na API (opcional com Swagger)

Acesse o Swagger em:

[http://localhost:8000/docs](http://localhost:8000/docs)

Use o bot√£o **"Authorize"** e insira:

- **Usu√°rio:** `admin`
- **Senha:** `abc123@abc`

O Swagger armazenar√° o token JWT automaticamente para requisi√ß√µes futuras.

> ‚ö†Ô∏è Essa etapa √© necess√°ria apenas para testar a API manualmente. O scraper j√° est√° configurado para autenticar automaticamente.

### 6. Execute o scraper

Com a API rodando, execute o seguinte comando para iniciar a coleta e envio de dados:

```bash
python ingestion/main_scraper.py producao --ano_inicial 1970 --ano_final 2023
```

O scraper ir√°:
- Coletar os dados da Embrapa via scraping;
- Realizar login na API (programaticamente);
- Enviar os dados por POST para os endpoints correspondentes;
- A API armazenar√° os dados no banco de dados SQLite (`vitivinicultura.db`).


---

## üß¢ Coleta de Dados com Scraper

O m√≥dulo `ingestion/` cont√©m o c√≥digo respons√°vel por realizar a coleta automatizada de dados da Embrapa e envi√°-los para a API, que se encarrega de armazenar as informa√ß√µes no banco de dados.

### ‚öôÔ∏è Como funciona o scraper

- A coleta √© realizada via **web scraping**, utilizando `requests` e `BeautifulSoup`;
- Os dados extra√≠dos s√£o convertidos em objetos Python estruturados;
- O m√≥dulo autentica automaticamente na API para obter um token JWT v√°lido;
- Os dados s√£o enviados para os endpoints correspondentes da API utilizando `requests.post()` com o token no cabe√ßalho;
- A API realiza a valida√ß√£o e grava os dados no banco `vitivinicultura.db`.

### ‚ñ∂Ô∏è Exemplo de execu√ß√£o

```bash
python ingestion/main_scraper.py producao --ano_inicial 1970 --ano_final 2023
```

Esse comando far√° a raspagem dos dados de produ√ß√£o vitivin√≠cola entre os anos de 1970 e 2023, e os enviar√° automaticamente para o endpoint `/producao/` da API.

### üîí Autentica√ß√£o automatizada

Durante a execu√ß√£o, o scraper:
- Realiza login via `/auth/login` com as credenciais padr√£o (`admin` / `abc123@abc`);
- Recebe o token JWT da API;
- Insere o token nos headers de todas as requisi√ß√µes subsequentes.

### üí° Observa√ß√µes importantes

- **A API precisa estar em execu√ß√£o** no momento da coleta. Caso contr√°rio, ocorrer√° erro de conex√£o (`ConnectionRefusedError`).
- O scraper atualmente suporta as seguintes entidades: `producao`, `processamento`, `comercializacao`, `importacao`, `exportacao`.
- A arquitetura adotada garante que todas as regras de neg√≥cio e valida√ß√µes fiquem centralizadas na API.

---

## üì° Executando a API

A API foi desenvolvida com **FastAPI** e disponibiliza os dados coletados de forma estruturada por meio de endpoints organizados por dom√≠nio (produ√ß√£o, processamento, comercializa√ß√£o etc).

### ‚ñ∂Ô∏è Como iniciar o servidor local

Certifique-se de estar com o ambiente virtual ativado e execute:

```bash
uvicorn app.main:app --reload
```

O par√¢metro `--reload` ativa o modo de desenvolvimento, permitindo que a API seja recarregada automaticamente a cada altera√ß√£o no c√≥digo.

### üîé Acessando a documenta√ß√£o interativa

FastAPI oferece duas interfaces autom√°ticas para explorar os endpoints dispon√≠veis:

- **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **Redoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### üì¶ Organiza√ß√£o dos Endpoints

Os endpoints est√£o organizados por m√≥dulo tem√°tico, como por exemplo:

- `/producao`
- `/processamento`
- `/comercializacao`
- `/importacao`
- `/exportacao`
- `/previsao`

Cada rota possui m√©todos HTTP t√≠picos de uma API REST (GET, POST, PUT, DELETE), e os dados retornados est√£o em formato JSON.

> ‚úÖ Todos os modelos de entrada e sa√≠da foram validados com Pydantic, garantindo seguran√ßa e integridade dos dados.

---

# üîê Autentica√ß√£o da API

A autentica√ß√£o da API garante que apenas usu√°rios autorizados possam acessar os recursos disponibilizados pela aplica√ß√£o. Esta funcionalidade est√° implementada no m√≥dulo `app/auth.py`.

## ‚öôÔ∏è Vis√£o Geral da Implementa√ß√£o

- A autentica√ß√£o √© baseada em **JWT (JSON Web Tokens)**;
- **Todas as rotas** da API exigem autentica√ß√£o para serem acessadas;
- O login √© realizado por meio do endpoint `/auth/login`, utilizando **usu√°rio e senha**;
- O token JWT gerado √© armazenado automaticamente pela interface Swagger UI e utilizado nas requisi√ß√µes subsequentes;
- As rotas s√£o protegidas com o uso de `Depends(get_current_user)`, garantindo que apenas usu√°rios autenticados possam acess√°-las.

## üîë Credenciais de Acesso (Ambiente Local)

- **Usu√°rio:** `admin`
- **Senha:** `abc123@abc`

Essas credenciais foram configuradas para testes locais e permitem a autentica√ß√£o completa no ambiente de desenvolvimento.

## üß™ Como Autenticar Usando o Swagger UI

1. Acesse: [http://localhost:8000/docs](http://localhost:8000/docs)
2. Clique no bot√£o **"Authorize"** no canto superior direito da interface
3. Insira as credenciais solicitadas (usu√°rio e senha)
4. O Swagger ir√° gerar e armazenar automaticamente o token JWT para uso nas requisi√ß√µes subsequentes

> ‚ÑπÔ∏è A autentica√ß√£o est√° **ativada por padr√£o**. Requisi√ß√µes sem autentica√ß√£o resultam em erro HTTP 401 (Unauthorized).

Esta abordagem garante seguran√ßa b√°sica para ambientes de teste e estrutura a base para futuras implementa√ß√µes mais robustas, como controle de permiss√µes por perfil ou autentica√ß√£o integrada com provedores externos.

---

# üßπ Endpoints Dispon√≠veis

A API foi estruturada em torno de m√≥dulos tem√°ticos que correspondem √†s principais categorias de dados extra√≠dos da Embrapa. Cada m√≥dulo representa uma √°rea da cadeia vitivin√≠cola e est√° dispon√≠vel como um conjunto de rotas RESTful.

## üìÅ Grupos de Endpoints

Os dados est√£o organizados e acess√≠veis por meio dos seguintes caminhos base:

- **`/producao`** ‚Äì Dados sobre a produ√ß√£o vitivin√≠cola por ano, tipo de uva, estado, entre outros;
- **`/processamento`** ‚Äì Informa√ß√µes sobre o processamento industrial das uvas;
- **`/comercializacao`** ‚Äì Dados referentes √† comercializa√ß√£o interna dos produtos vitivin√≠colas;
- **`/importacao`** ‚Äì Estat√≠sticas sobre a importa√ß√£o de produtos do setor;
- **`/exportacao`** ‚Äì Dados relacionados √† exporta√ß√£o de vinhos e derivados.
- `Previs√£o` ‚Äì Endpoint de previs√£o de produ√ß√£o futura com base em s√©ries temporais usando modelo de IA (LSTM).


Cada rota disponibiliza as opera√ß√µes b√°sicas:
- `GET /` ‚Äì Listar todos os registros
- `GET /{id}` ‚Äì Consultar registro por ID
- `POST /` ‚Äì Inserir novo registro / Fazer um requisi√ß√£o de previs√£o
- `PUT /{id}` ‚Äì Atualizar registro existente
- `DELETE /{id}` ‚Äì Remover registro

> ‚ö†Ô∏è Todas as rotas exigem autentica√ß√£o JWT v√°lida. Use o Swagger UI para autenticar e testar os endpoints facilmente.

## üß™ Testando na pr√°tica

Ao autenticar-se com sucesso via `/auth/login`, voc√™ pode explorar e testar todos os endpoints diretamente na interface:

- [http://localhost:8000/docs](http://localhost:8000/docs)
- [http://localhost:8000/redoc](http://localhost:8000/redoc)

Cada endpoint foi documentado com exemplos de entrada e retorno, permitindo f√°cil compreens√£o e valida√ß√£o da estrutura de dados retornada pela API.

---

# üìä Modelo de Previs√£o LSTM via API

Como parte do desafio da **Fase 3 do Tech Challenge**, foi incorporado um modelo preditivo de s√©ries temporais utilizando a arquitetura **LSTM (Long Short-Term Memory)** da biblioteca `Keras`.

Esse modelo √© exposto via API em um endpoint dedicado, e foi treinado com os dados hist√≥ricos tratados da produ√ß√£o vitivin√≠cola.

---

## üåü Objetivo do Modelo

O modelo tem como prop√≥sito prever os valores futuros de produ√ß√£o com base em dados hist√≥ricos (ano a ano), utilizando s√©ries temporais univariadas.

Isso permite gerar **insights antecipados** para:
- Planejamento da safra
- Log√≠stica de armazenamento
- Tomada de decis√£o estrat√©gica

---

## üîç Endpoint da API

- **Rota:** `POST /predict/lstm`
- **Descri√ß√£o:** Retorna a previs√£o do pr√≥ximo valor baseado na sequ√™ncia informada.
- **Autentica√ß√£o:** Opcional

### üìÇ Corpo da requisi√ß√£o
```json
{
  "valores": [12500.0, 12700.0, 13100.0]
}
```

### üìä Exemplo de resposta
```json
{
  "prediction": 13350.5
}
```

---

## üõ†Ô∏è Como o modelo foi treinado

O modelo foi treinado a partir da base `producoes` ap√≥s o pr√©-processamento dos dados.

### Etapas:
1. Extra√ß√£o dos dados da tabela `producoes` (via SQLAlchemy)
2. Agrupamento por ano e somat√≥rio da coluna `quantidade`
3. Normaliza√ß√£o da s√©rie temporal
4. Treinamento com LSTM (camada oculta com 50 neur√¥nios)
5. Salvamento do modelo com `model.save('lstm_model.h5')`
6. Disponibiliza√ß√£o do modelo na API usando FastAPI


---
# üìò Diagramas do Projeto

Para facilitar a compreens√£o da arquitetura e dos fluxos do sistema, foram desenvolvidos dois diagramas que representam visualmente a estrutura atual e a proje√ß√£o futura da solu√ß√£o.

## üß± Diagrama de M√≥dulos (`modulos.png`)

Este diagrama apresenta a estrutura modular da API, destacando os componentes respons√°veis por:

- Coleta e armazenamento dos dados (`scraper/` e `vitivinicultura.db`)
- Organiza√ß√£o das funcionalidades por dom√≠nio (produ√ß√£o, comercializa√ß√£o, etc.)
- Separa√ß√£o em camadas como `models`, `schemas`, `crud` e `routers`

Essa visualiza√ß√£o refor√ßa a ado√ß√£o de boas pr√°ticas de arquitetura, promovendo coes√£o interna e separa√ß√£o de responsabilidades.

## üöÄ Arquitetura P√≥s-Fase 1 (`pos_fase1.png`)

Representa a vis√£o de futuro da aplica√ß√£o, com os seguintes componentes:

- Coleta de dados automatizada e peri√≥dica
- Armazenamento estruturado e seguro
- Exposi√ß√£o via API p√∫blica (FastAPI)
- Integra√ß√£o com um sistema de frontend para visualiza√ß√£o e an√°lise
- Potencial uso da base como fonte de dados para modelos de Machine Learning

> üñºÔ∏è Ambos os diagramas est√£o localizados na pasta `/docs` do projeto e podem ser usados como material de apoio em apresenta√ß√µes ou documenta√ß√£o t√©cnica.

---

# üîÆ Futuras Melhorias

Embora o projeto esteja funcional e atenda aos requisitos da Fase 1, existem diversas oportunidades para aprimoramento e evolu√ß√£o da solu√ß√£o. Abaixo est√£o listadas algumas melhorias planejadas ou recomendadas para fases futuras:

## ‚öôÔ∏è T√©cnicas e Arquitetura

- Substitui√ß√£o do banco de dados SQLite por uma solu√ß√£o mais robusta como **PostgreSQL** ou **MySQL**, especialmente para ambientes de produ√ß√£o;
- Separa√ß√£o de ambientes de desenvolvimento e produ√ß√£o utilizando arquivos `.env` e configura√ß√£o din√¢mica via `pydantic.BaseSettings`;
- Estrutura√ß√£o de um **pipeline de ingest√£o automatizado** que execute o scraper periodicamente;
- Implementa√ß√£o de testes automatizados com `pytest` e cobertura m√≠nima de c√≥digo;
- Ado√ß√£o de pr√°ticas de CI/CD para valida√ß√£o e deploy cont√≠nuo da API.

## üîê Seguran√ßa

- Cria√ß√£o de m√∫ltiplos usu√°rios e controle de permiss√µes por perfil;
- Prote√ß√£o adicional para endpoints sens√≠veis;
- Integra√ß√£o futura com provedores de autentica√ß√£o externa (OAuth2, SSO etc.).


## üåê Infraestrutura e Interface

- Cria√ß√£o de um frontend (ex: com React ou Streamlit) para visualiza√ß√£o dos dados da API;
- Containeriza√ß√£o completa com Docker Compose para execu√ß√£o integrada da API, banco de dados e frontend;
- Deploy em nuvem (Heroku, Render, AWS ou GCP) com link p√∫blico acess√≠vel.





